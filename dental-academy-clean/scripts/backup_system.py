#!/usr/bin/env python3
"""
–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –±—ç–∫–∞–ø–æ–≤ –¥–ª—è Mentora
–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ–∞–π–ª–æ–≤
"""

import os
import sys
import json
import shutil
import gzip
import schedule
import time
from datetime import datetime, timedelta
from pathlib import Path
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backup_system.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BackupSystem:
    """–°–∏—Å—Ç–µ–º–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self):
        self.backup_dir = Path("backups")
        self.backup_dir.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        (self.backup_dir / "database").mkdir(exist_ok=True)
        (self.backup_dir / "files").mkdir(exist_ok=True)
        (self.backup_dir / "logs").mkdir(exist_ok=True)
    
    def create_database_backup(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            from app import app
            from models import db, User, Contact, Profession, CountryAnalytics, DeviceAnalytics
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = self.backup_dir / "database" / f"db_backup_{timestamp}.json"
            
            with app.app_context():
                backup_data = {
                    'metadata': {
                        'timestamp': timestamp,
                        'version': '1.0',
                        'created_by': 'backup_system'
                    },
                    'tables': {}
                }
                
                # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
                models = [
                    ('users', User),
                    ('contacts', Contact),
                    ('professions', Profession),
                    ('country_analytics', CountryAnalytics),
                    ('device_analytics', DeviceAnalytics)
                ]
                
                for table_name, model in models:
                    try:
                        records = []
                        for record in model.query.all():
                            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å
                            record_dict = {}
                            for column in model.__table__.columns:
                                value = getattr(record, column.name)
                                if isinstance(value, datetime):
                                    value = value.isoformat()
                                record_dict[column.name] = value
                            records.append(record_dict)
                        
                        backup_data['tables'][table_name] = {
                            'count': len(records),
                            'records': records
                        }
                        
                        logger.info(f"‚úÖ –¢–∞–±–ª–∏—Ü–∞ {table_name}: {len(records)} –∑–∞–ø–∏—Å–µ–π")
                        
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã {table_name}: {str(e)}")
                        backup_data['tables'][table_name] = {
                            'count': 0,
                            'records': [],
                            'error': str(e)
                        }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é
                with open(backup_file, 'w', encoding='utf-8') as f:
                    json.dump(backup_data, f, ensure_ascii=False, indent=2)
                
                # –°–∂–∏–º–∞–µ–º —Ñ–∞–π–ª
                compressed_file = f"{backup_file}.gz"
                with open(backup_file, 'rb') as f_in:
                    with gzip.open(compressed_file, 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
                
                # –£–¥–∞–ª—è–µ–º –Ω–µ—Å–∂–∞—Ç—ã–π —Ñ–∞–π–ª
                backup_file.unlink()
                
                logger.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –ë–î —Å–æ–∑–¥–∞–Ω–∞: {compressed_file}")
                return str(compressed_file)
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –ë–î: {str(e)}")
            return None
    
    def create_files_backup(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –≤–∞–∂–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_file = self.backup_dir / "files" / f"files_backup_{timestamp}.tar.gz"
            
            # –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
            important_paths = [
                'config.py',
                'models.py',
                'app.py',
                'requirements.txt',
                'render.yaml',
                'templates/',
                'static/',
                'translations/',
                'scripts/'
            ]
            
            # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
            import tarfile
            
            with tarfile.open(backup_file, 'w:gz') as tar:
                for path in important_paths:
                    if os.path.exists(path):
                        tar.add(path, arcname=path)
                        logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω –≤ –∞—Ä—Ö–∏–≤: {path}")
                    else:
                        logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
            
            logger.info(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Ñ–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω–∞: {backup_file}")
            return str(backup_file)
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ —Ñ–∞–π–ª–æ–≤: {str(e)}")
            return None
    
    def restore_database_backup(self, backup_file):
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏"""
        try:
            from app import app
            from models import db, User, Contact, Profession, CountryAnalytics, DeviceAnalytics
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–∂–∞—Ç –ª–∏ —Ñ–∞–π–ª
            if backup_file.endswith('.gz'):
                import gzip
                with gzip.open(backup_file, 'rt', encoding='utf-8') as f:
                    backup_data = json.load(f)
            else:
                with open(backup_file, 'r', encoding='utf-8') as f:
                    backup_data = json.load(f)
            
            with app.app_context():
                # –û—á–∏—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
                db.session.query(User).delete()
                db.session.query(Contact).delete()
                db.session.query(Profession).delete()
                db.session.query(CountryAnalytics).delete()
                db.session.query(DeviceAnalytics).delete()
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                models_map = {
                    'users': User,
                    'contacts': Contact,
                    'professions': Profession,
                    'country_analytics': CountryAnalytics,
                    'device_analytics': DeviceAnalytics
                }
                
                for table_name, model in models_map.items():
                    if table_name in backup_data['tables']:
                        table_data = backup_data['tables'][table_name]
                        if 'error' in table_data:
                            logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—É {table_name} –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏: {table_data['error']}")
                            continue
                        
                        for record_data in table_data['records']:
                            try:
                                # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏
                                record = model()
                                for key, value in record_data.items():
                                    if hasattr(record, key):
                                        setattr(record, key, value)
                                
                                db.session.add(record)
                                
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–ø–∏—Å–∏ –≤ {table_name}: {str(e)}")
                        
                        logger.info(f"‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ {len(table_data['records'])} –∑–∞–ø–∏—Å–µ–π –≤ {table_name}")
                
                db.session.commit()
                logger.info("‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
                return True
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î: {str(e)}")
            return False
    
    def cleanup_old_backups(self, days_to_keep=30):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            
            for backup_type in ['database', 'files']:
                backup_path = self.backup_dir / backup_type
                if not backup_path.exists():
                    continue
                
                for backup_file in backup_path.iterdir():
                    if backup_file.is_file():
                        file_time = datetime.fromtimestamp(backup_file.stat().st_mtime)
                        if file_time < cutoff_date:
                            backup_file.unlink()
                            logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ —Å—Ç–∞—Ä–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è: {backup_file.name}")
            
            logger.info(f"‚úÖ –û—á–∏—Å—Ç–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π —Å—Ç–∞—Ä—à–µ {days_to_keep} –¥–Ω–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –∫–æ–ø–∏–π: {str(e)}")
    
    def get_backup_status(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π"""
        try:
            status = {
                'database_backups': [],
                'files_backups': [],
                'total_size': 0
            }
            
            for backup_type in ['database', 'files']:
                backup_path = self.backup_dir / backup_type
                if backup_path.exists():
                    for backup_file in backup_path.iterdir():
                        if backup_file.is_file():
                            file_info = {
                                'name': backup_file.name,
                                'size': backup_file.stat().st_size,
                                'created': datetime.fromtimestamp(backup_file.stat().st_mtime).isoformat()
                            }
                            status[f'{backup_type}_backups'].append(file_info)
                            status['total_size'] += file_info['size']
            
            return status
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞: {str(e)}")
            return None
    
    def schedule_backups(self):
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π"""
        try:
            # –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è –ë–î –≤ 2:00
            schedule.every().day.at("02:00").do(self.create_database_backup)
            
            # –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–∞—è —Ä–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Ñ–∞–π–ª–æ–≤ –≤ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –≤ 3:00
            schedule.every().sunday.at("03:00").do(self.create_files_backup)
            
            # –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∫–æ–ø–∏–π –≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ –≤ 4:00
            schedule.every().monday.at("04:00").do(self.cleanup_old_backups)
            
            logger.info("‚úÖ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
            while True:
                schedule.run_pending()
                time.sleep(60)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
                
        except KeyboardInterrupt:
            logger.info("‚èπÔ∏è –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞: {str(e)}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–°–∏—Å—Ç–µ–º–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è Mentora')
    parser.add_argument('action', choices=['backup', 'restore', 'status', 'schedule', 'cleanup'],
                       help='–î–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è')
    parser.add_argument('--file', help='–§–∞–π–ª —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è')
    parser.add_argument('--days', type=int, default=30, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–ø–∏–π')
    
    args = parser.parse_args()
    
    backup_system = BackupSystem()
    
    if args.action == 'backup':
        logger.info("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π...")
        db_backup = backup_system.create_database_backup()
        files_backup = backup_system.create_files_backup()
        
        if db_backup and files_backup:
            logger.info("‚úÖ –í—Å–µ —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π")
    
    elif args.action == 'restore':
        if not args.file:
            logger.error("‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —Ñ–∞–π–ª —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏")
            return
        
        logger.info(f"üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ {args.file}...")
        if backup_system.restore_database_backup(args.file):
            logger.info("‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è")
    
    elif args.action == 'status':
        status = backup_system.get_backup_status()
        if status:
            print(json.dumps(status, indent=2, ensure_ascii=False))
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞")
    
    elif args.action == 'schedule':
        logger.info("‚è∞ –ó–∞–ø—É—Å–∫ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π...")
        backup_system.schedule_backups()
    
    elif args.action == 'cleanup':
        logger.info(f"üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω—ã—Ö –∫–æ–ø–∏–π —Å—Ç–∞—Ä—à–µ {args.days} –¥–Ω–µ–π...")
        backup_system.cleanup_old_backups(args.days)

if __name__ == '__main__':
    main()
