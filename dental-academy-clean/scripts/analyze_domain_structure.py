#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–º–µ–Ω–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
–í—ã—è–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –ø–æ—Ç–µ—Ä–µ–π –¥–∞–Ω–Ω—ã—Ö
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app import app
from models import db, BIGDomain, Question, DiagnosticResponse, PersonalLearningPlan
import json
from collections import defaultdict

def analyze_domain_structure():
    """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–º–µ–Ω–æ–≤"""
    
    with app.app_context():
        print("üîç –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –î–û–ú–ï–ù–û–í")
        print("=" * 50)
        
        # 1. –ê–Ω–∞–ª–∏–∑ –¥–æ–º–µ–Ω–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        print("\n1. –î–û–ú–ï–ù–´ –í –ë–ê–ó–ï –î–ê–ù–ù–´–•:")
        domains = BIGDomain.query.all()
        print(f"   –í—Å–µ–≥–æ –¥–æ–º–µ–Ω–æ–≤: {len(domains)}")
        
        domain_info = {}
        for domain in domains:
            domain_info[domain.code] = {
                'id': domain.id,
                'name': domain.name,
                'code': domain.code,
                'category': domain.category,
                'weight': domain.weight_percentage,
                'is_active': domain.is_active
            }
            print(f"   - {domain.code}: {domain.name} (ID: {domain.id}, –≤–µ—Å: {domain.weight_percentage}%)")
        
        # 2. –ê–Ω–∞–ª–∏–∑ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –¥–æ–º–µ–Ω–∞–º
        print("\n2. –í–û–ü–†–û–°–´ –ü–û –î–û–ú–ï–ù–ê–ú:")
        questions_by_domain = defaultdict(list)
        questions = Question.query.all()
        
        for question in questions:
            domain_code = question.domain
            questions_by_domain[domain_code].append(question.id)
        
        print(f"   –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(questions)}")
        for domain_code, question_ids in questions_by_domain.items():
            print(f"   - {domain_code}: {len(question_ids)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        # 3. –ê–Ω–∞–ª–∏–∑ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤
        print("\n3. –î–ò–ê–ì–ù–û–°–¢–ò–ß–ï–°–ö–ò–ï –û–¢–í–ï–¢–´ –ü–û –î–û–ú–ï–ù–ê–ú:")
        responses_by_domain = defaultdict(int)
        responses = DiagnosticResponse.query.all()
        
        for response in responses:
            if response.question and response.question.domain:
                responses_by_domain[response.question.domain] += 1
        
        print(f"   –í—Å–µ–≥–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤: {len(responses)}")
        for domain_code, count in responses_by_domain.items():
            print(f"   - {domain_code}: {count} –æ—Ç–≤–µ—Ç–æ–≤")
        
        # 4. –ê–Ω–∞–ª–∏–∑ –ø–ª–∞–Ω–æ–≤ –æ–±—É—á–µ–Ω–∏—è
        print("\n4. –ü–õ–ê–ù–´ –û–ë–£–ß–ï–ù–ò–Ø:")
        plans = PersonalLearningPlan.query.all()
        print(f"   –í—Å–µ–≥–æ –ø–ª–∞–Ω–æ–≤ –æ–±—É—á–µ–Ω–∏—è: {len(plans)}")
        
        domain_analysis_stats = defaultdict(int)
        weak_domains_stats = defaultdict(int)
        strong_domains_stats = defaultdict(int)
        
        for plan in plans:
            if plan.domain_analysis:
                try:
                    analysis = plan.get_domain_analysis()
                    if analysis:
                        for domain_code in analysis.keys():
                            domain_analysis_stats[domain_code] += 1
                except:
                    pass
            
            if plan.weak_domains:
                try:
                    weak_domains = plan.get_weak_domains()
                    if weak_domains:
                        for domain_code in weak_domains:
                            weak_domains_stats[domain_code] += 1
                except:
                    pass
            
            if plan.strong_domains:
                try:
                    strong_domains = plan.get_strong_domains()
                    if strong_domains:
                        for domain_code in strong_domains:
                            strong_domains_stats[domain_code] += 1
                except:
                    pass
        
        print("   –î–æ–º–µ–Ω—ã –≤ –∞–Ω–∞–ª–∏–∑–µ:")
        for domain_code, count in domain_analysis_stats.items():
            print(f"     - {domain_code}: {count} –ø–ª–∞–Ω–æ–≤")
        
        print("   –°–ª–∞–±—ã–µ –¥–æ–º–µ–Ω—ã:")
        for domain_code, count in weak_domains_stats.items():
            print(f"     - {domain_code}: {count} –ø–ª–∞–Ω–æ–≤")
        
        print("   –°–∏–ª—å–Ω—ã–µ –¥–æ–º–µ–Ω—ã:")
        for domain_code, count in strong_domains_stats.items():
            print(f"     - {domain_code}: {count} –ø–ª–∞–Ω–æ–≤")
        
        # 5. –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
        print("\n5. –í–´–Ø–í–õ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        domain_codes = [d.code for d in domains]
        duplicates = [code for code in set(domain_codes) if domain_codes.count(code) > 1]
        if duplicates:
            print(f"   ‚ùå –î–£–ë–õ–ò–†–£–Æ–©–ò–ï–°–Ø –î–û–ú–ï–ù–´: {duplicates}")
        else:
            print("   ‚úÖ –î—É–±–ª–∏—Ä—É—é—â–∏—Ö—Å—è –¥–æ–º–µ–Ω–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –¥–æ–º–µ–Ω–æ–≤
        expected_domains = set(BIGDomain.DOMAIN_CODES.keys())
        existing_domains = set(domain_codes)
        missing_domains = expected_domains - existing_domains
        
        if missing_domains:
            print(f"   ‚ùå –û–¢–°–£–¢–°–¢–í–£–Æ–©–ò–ï –î–û–ú–ï–ù–´: {list(missing_domains)}")
        else:
            print("   ‚úÖ –í—Å–µ –æ–∂–∏–¥–∞–µ–º—ã–µ –¥–æ–º–µ–Ω—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
        inactive_domains = [d.code for d in domains if not d.is_active]
        if inactive_domains:
            print(f"   ‚ö†Ô∏è  –ù–ï–ê–ö–¢–ò–í–ù–´–ï –î–û–ú–ï–ù–´: {inactive_domains}")
        
        # 6. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö
        print("\n6. –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–¢–ï–†–ò –î–ê–ù–ù–´–•:")
        
        # –ü–æ–¥—Å—á–µ—Ç –¥–æ–º–µ–Ω–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏
        domains_with_questions = len(questions_by_domain)
        domains_with_responses = len(responses_by_domain)
        domains_in_plans = len(domain_analysis_stats)
        
        print(f"   –î–æ–º–µ–Ω—ã —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏: {domains_with_questions}")
        print(f"   –î–æ–º–µ–Ω—ã —Å –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏: {domains_with_responses}")
        print(f"   –î–æ–º–µ–Ω—ã –≤ –ø–ª–∞–Ω–∞—Ö –æ–±—É—á–µ–Ω–∏—è: {domains_in_plans}")
        
        if domains_in_plans < 30:
            print(f"   ‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–ë–õ–ï–ú–ê: –¢–æ–ª—å–∫–æ {domains_in_plans} –¥–æ–º–µ–Ω–æ–≤ –≤ –ø–ª–∞–Ω–∞—Ö –æ–±—É—á–µ–Ω–∏—è –∏–∑ 30!")
        
        # 7. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("\n7. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        
        if missing_domains:
            print("   - –°–æ–∑–¥–∞—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–æ–º–µ–Ω—ã")
        
        if duplicates:
            print("   - –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –¥–æ–º–µ–Ω—ã")
        
        if domains_in_plans < 30:
            print("   - –û–±–Ω–æ–≤–∏—Ç—å –≤—Å–µ –ø–ª–∞–Ω—ã –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤—Å–µ—Ö 30 –¥–æ–º–µ–Ω–æ–≤")
        
        if inactive_domains:
            print("   - –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –¥–æ–º–µ–Ω—ã –∏–ª–∏ —É–¥–∞–ª–∏—Ç—å –∏—Ö")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report = {
            'total_domains': len(domains),
            'expected_domains': 30,
            'missing_domains': list(missing_domains),
            'duplicate_domains': duplicates,
            'inactive_domains': inactive_domains,
            'domains_with_questions': domains_with_questions,
            'domains_with_responses': domains_with_responses,
            'domains_in_plans': domains_in_plans,
            'domain_details': domain_info,
            'questions_by_domain': dict(questions_by_domain),
            'responses_by_domain': dict(responses_by_domain),
            'plans_analysis': dict(domain_analysis_stats)
        }
        
        with open('analysis/domain_analysis_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: analysis/domain_analysis_report.json")
        
        return report

if __name__ == '__main__':
    analyze_domain_structure() 