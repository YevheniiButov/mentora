"""add daily assignments model

Revision ID: eadf0bc80aff
Revises: 66cd825725a2
Create Date: 2025-11-04 10:04:55.786736

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = 'eadf0bc80aff'
down_revision = '66cd825725a2'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Get connection and handle transaction state
    connection = op.get_bind()
    
    # Rollback any failed transaction
    try:
        connection.rollback()
    except Exception:
        pass
    
    # Create daily_assignments table (if it doesn't exist)
    try:
        op.create_table('daily_assignments',
            sa.Column('id', sa.Integer(), nullable=False),
            sa.Column('user_id', sa.Integer(), nullable=False),
            sa.Column('assignment_date', sa.Date(), nullable=False),
            sa.Column('assignment_type', sa.String(length=20), nullable=False),
            sa.Column('item_ids', sa.Text(), nullable=False),
            sa.Column('completed', sa.Boolean(), nullable=True),
            sa.Column('completed_at', sa.DateTime(), nullable=True),
            sa.Column('attempts', sa.Integer(), nullable=True),
            sa.Column('created_at', sa.DateTime(), nullable=True),
            sa.Column('updated_at', sa.DateTime(), nullable=True),
            sa.ForeignKeyConstraint(['user_id'], ['user.id'], name='fk_daily_assignments_user_id', ondelete='CASCADE'),
            sa.PrimaryKeyConstraint('id', name='pk_daily_assignments'),
            sa.UniqueConstraint('user_id', 'assignment_date', 'assignment_type', name='_user_date_type_uc')
        )
        op.create_index(op.f('ix_daily_assignments_assignment_date'), 'daily_assignments', ['assignment_date'], unique=False)
        op.create_index(op.f('ix_daily_assignments_assignment_type'), 'daily_assignments', ['assignment_type'], unique=False)
    except Exception:
        # Table might already exist, skip
        pass
    
    # Удаляем временную таблицу, если она существует
    try:
        op.drop_table('_alembic_tmp_big_domain')
    except Exception:
        # Таблица может не существовать, игнорируем ошибку
        pass
    
    # Check if big_domain table exists and what changes are needed
    # Use raw SQL to avoid transaction issues
    connection = op.get_bind()
    
    # Get list of tables using raw SQL (avoids transaction issues)
    result = connection.execute(sa.text("""
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_type = 'BASE TABLE'
    """))
    tables = [row[0] for row in result]
    
    if 'big_domain' in tables:
        # Check code column type using raw SQL
        code_result = connection.execute(sa.text("""
            SELECT data_type, character_maximum_length 
            FROM information_schema.columns 
            WHERE table_name = 'big_domain' 
            AND column_name = 'code'
        """))
        code_row = code_result.fetchone()
        code_needs_update = False
        if code_row and code_row[1] == 20:
            code_needs_update = True
        
        # Check if foreign key exists using raw SQL
        fk_result = connection.execute(sa.text("""
            SELECT constraint_name 
            FROM information_schema.table_constraints 
            WHERE table_name = 'big_domain' 
            AND constraint_type = 'FOREIGN KEY'
            AND constraint_name = 'fk_big_domain_category_id'
        """))
        fk_exists = fk_result.fetchone() is not None
        
        if code_needs_update or not fk_exists:
            with op.batch_alter_table('big_domain', schema=None) as batch_op:
                if code_needs_update:
                    batch_op.alter_column('code',
                           existing_type=sa.VARCHAR(length=20),
                           type_=sa.String(length=50),
                           existing_nullable=False)
                if not fk_exists:
                    batch_op.create_foreign_key('fk_big_domain_category_id', 'domain_category', ['category_id'], ['id'])

    # Check if forum_topics table exists and foreign key is needed
    if 'forum_topics' in tables:
        fk_result = connection.execute(sa.text("""
            SELECT constraint_name 
            FROM information_schema.table_constraints 
            WHERE table_name = 'forum_topics' 
            AND constraint_type = 'FOREIGN KEY'
            AND constraint_name = 'fk_forum_topics_deleted_by'
        """))
        if fk_result.fetchone() is None:
            with op.batch_alter_table('forum_topics', schema=None) as batch_op:
                batch_op.create_foreign_key('fk_forum_topics_deleted_by', 'user', ['deleted_by'], ['id'])

    # Check if incoming_emails table exists and source_account column needs update
    if 'incoming_emails' in tables:
        col_result = connection.execute(sa.text("""
            SELECT is_nullable 
            FROM information_schema.columns 
            WHERE table_name = 'incoming_emails' 
            AND column_name = 'source_account'
        """))
        col_row = col_result.fetchone()
        if col_row and col_row[0] == 'YES':  # Column is nullable
                with op.batch_alter_table('incoming_emails', schema=None) as batch_op:
                    batch_op.alter_column('source_account',
                           existing_type=sa.VARCHAR(length=50),
                           nullable=False,
                           existing_server_default=sa.text("'info'"))

    # Check if learning_path table exists and id column needs update
    if 'learning_path' in tables:
        id_result = connection.execute(sa.text("""
            SELECT data_type 
            FROM information_schema.columns 
            WHERE table_name = 'learning_path' 
            AND column_name = 'id'
        """))
        id_row = id_result.fetchone()
        # Only alter if it's still VARCHAR/character varying
        if id_row and 'varying' in id_row[0].lower():
                with op.batch_alter_table('learning_path', schema=None) as batch_op:
                    batch_op.alter_column('id',
                           existing_type=sa.VARCHAR(length=50),
                           type_=sa.Integer(),
                           existing_nullable=False,
                           autoincrement=True)

    # Check if page_views table exists and foreign key is needed
    if 'page_views' in tables:
        fk_result = connection.execute(sa.text("""
            SELECT constraint_name 
            FROM information_schema.table_constraints 
            WHERE table_name = 'page_views' 
            AND constraint_type = 'FOREIGN KEY'
            AND constraint_name = 'fk_page_views_session_id'
        """))
        if fk_result.fetchone() is None:
            with op.batch_alter_table('page_views', schema=None) as batch_op:
                batch_op.create_foreign_key('fk_page_views_session_id', 'user_sessions', ['session_id'], ['session_id'])

    # Check if registration_logs table exists and columns need to be dropped
    if 'registration_logs' in tables:
        col_result = connection.execute(sa.text("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_name = 'registration_logs' 
            AND column_name IN ('field', 'error_message', 'form_data', 'error_code')
        """))
        columns_to_drop = [row[0] for row in col_result]
        
        if columns_to_drop:
            with op.batch_alter_table('registration_logs', schema=None) as batch_op:
                for col in columns_to_drop:
                    batch_op.drop_column(col)

    # Check if user table exists and what changes are needed
    if 'user' in tables:
        needs_changes = False
        changes = {}
        
        # Check deleted_at column type
        deleted_at_result = connection.execute(sa.text("""
            SELECT data_type 
            FROM information_schema.columns 
            WHERE table_name = 'user' 
            AND column_name = 'deleted_at'
        """))
        deleted_at_row = deleted_at_result.fetchone()
        if deleted_at_row and 'timestamp' in deleted_at_row[0].lower() and 'without time zone' in deleted_at_row[0].lower():
            changes['deleted_at'] = True
            needs_changes = True
        
        # Check profile_public column nullable
        profile_result = connection.execute(sa.text("""
            SELECT is_nullable 
            FROM information_schema.columns 
            WHERE table_name = 'user' 
            AND column_name = 'profile_public'
        """))
        profile_row = profile_result.fetchone()
        if profile_row and profile_row[0] == 'NO':  # Column is NOT NULL
            changes['profile_public'] = True
            needs_changes = True
        
        # Check if index exists
        index_result = connection.execute(sa.text("""
            SELECT indexname 
            FROM pg_indexes 
            WHERE tablename = 'user' 
            AND indexname = 'ix_user_member_id'
        """))
        index_needed = index_result.fetchone() is None
        
        if needs_changes or index_needed:
            with op.batch_alter_table('user', schema=None) as batch_op:
                if changes.get('deleted_at'):
                    batch_op.alter_column('deleted_at',
                           existing_type=sa.TIMESTAMP(),
                           type_=sa.DateTime(),
                           existing_nullable=True)
                if changes.get('profile_public'):
                    batch_op.alter_column('profile_public',
                           existing_type=sa.BOOLEAN(),
                           nullable=True,
                           existing_server_default=sa.text("'1'"))
                if index_needed:
                    batch_op.create_index(batch_op.f('ix_user_member_id'), ['member_id'], unique=True)

    # Check if user_learning_progress table exists and learning_path_id needs update
    if 'user_learning_progress' in tables:
        lp_id_result = connection.execute(sa.text("""
            SELECT data_type 
            FROM information_schema.columns 
            WHERE table_name = 'user_learning_progress' 
            AND column_name = 'learning_path_id'
        """))
        lp_id_row = lp_id_result.fetchone()
        # Only alter if it's still VARCHAR/character varying
        if lp_id_row and 'varying' in lp_id_row[0].lower():
                with op.batch_alter_table('user_learning_progress', schema=None) as batch_op:
                    batch_op.alter_column('learning_path_id',
                           existing_type=sa.VARCHAR(length=50),
                           type_=sa.Integer(),
                           existing_nullable=False)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Drop daily_assignments table
    op.drop_index(op.f('ix_daily_assignments_assignment_type'), table_name='daily_assignments')
    op.drop_index(op.f('ix_daily_assignments_assignment_date'), table_name='daily_assignments')
    op.drop_table('daily_assignments')
    
    with op.batch_alter_table('user_learning_progress', schema=None) as batch_op:
        batch_op.alter_column('learning_path_id',
               existing_type=sa.Integer(),
               type_=sa.VARCHAR(length=50),
               existing_nullable=False)

    with op.batch_alter_table('user', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_user_member_id'))
        batch_op.alter_column('profile_public',
               existing_type=sa.BOOLEAN(),
               nullable=False,
               existing_server_default=sa.text("'1'"))
        batch_op.alter_column('deleted_at',
               existing_type=sa.DateTime(),
               type_=sa.TIMESTAMP(),
               existing_nullable=True)

    with op.batch_alter_table('registration_logs', schema=None) as batch_op:
        batch_op.add_column(sa.Column('error_code', sa.VARCHAR(length=100), nullable=True))
        batch_op.add_column(sa.Column('form_data', sa.TEXT(), nullable=True))
        batch_op.add_column(sa.Column('error_message', sa.TEXT(), nullable=True))
        batch_op.add_column(sa.Column('field', sa.VARCHAR(length=100), nullable=True))

    with op.batch_alter_table('page_views', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')

    with op.batch_alter_table('learning_path', schema=None) as batch_op:
        batch_op.alter_column('id',
               existing_type=sa.Integer(),
               type_=sa.VARCHAR(length=50),
               existing_nullable=False,
               autoincrement=True)

    with op.batch_alter_table('incoming_emails', schema=None) as batch_op:
        batch_op.alter_column('source_account',
               existing_type=sa.VARCHAR(length=50),
               nullable=True,
               existing_server_default=sa.text("'info'"))

    with op.batch_alter_table('forum_topics', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')

    with op.batch_alter_table('big_domain', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.alter_column('code',
               existing_type=sa.String(length=50),
               type_=sa.VARCHAR(length=20),
               existing_nullable=False)

    op.create_table('_alembic_tmp_big_domain',
    sa.Column('id', sa.INTEGER(), nullable=False),
    sa.Column('name', sa.VARCHAR(length=100), nullable=False),
    sa.Column('code', sa.VARCHAR(length=50), nullable=False),
    sa.Column('description', sa.TEXT(), nullable=True),
    sa.Column('weight_percentage', sa.FLOAT(), nullable=False),
    sa.Column('order', sa.INTEGER(), nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), nullable=True),
    sa.Column('created_at', sa.DATETIME(), nullable=True),
    sa.Column('category', sa.VARCHAR(length=50), nullable=True),
    sa.Column('exam_type', sa.VARCHAR(length=50), nullable=True),
    sa.Column('is_critical', sa.BOOLEAN(), server_default=sa.text('0'), nullable=True),
    sa.Column('subcategories', sa.TEXT(), nullable=True),
    sa.Column('historical_questions', sa.BOOLEAN(), server_default=sa.text('1'), nullable=True),
    sa.Column('open_book', sa.BOOLEAN(), server_default=sa.text('0'), nullable=True),
    sa.Column('category_id', sa.INTEGER(), nullable=True),
    sa.ForeignKeyConstraint(['category_id'], ['domain_category.id'], name='fk_big_domain_category_id'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('code'),
    sa.UniqueConstraint('name')
    )
    # ### end Alembic commands ###
