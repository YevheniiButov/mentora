# utils/adaptive_learning.py
"""
–°–∏—Å—Ç–µ–º–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
"""

import json
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import logging

class LearningStyle(Enum):
    """–°—Ç–∏–ª–∏ –æ–±—É—á–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"""
    VISUAL = "visual"           # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    ANALYTICAL = "analytical"   # –õ—é–±–∏—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    INTUITIVE = "intuitive"     # –ü–æ–ª–∞–≥–∞–µ—Ç—Å—è –Ω–∞ –∏–Ω—Ç—É–∏—Ü–∏—é
    SYSTEMATIC = "systematic"   # –°–ª–µ–¥—É–µ—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–∞–º
    EMPATHETIC = "empathetic"   # –§–æ–∫—É—Å –Ω–∞ —ç–º–æ—Ü–∏—è—Ö –ø–∞—Ü–∏–µ–Ω—Ç–∞

class SkillLevel(Enum):
    """–£—Ä–æ–≤–Ω–∏ –Ω–∞–≤—ã–∫–æ–≤"""
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"
    EXPERT = "expert"

@dataclass
class UserProfile:
    """–ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    user_id: int
    learning_style: LearningStyle
    skill_levels: Dict[str, SkillLevel]  # –ø–æ –æ–±–ª–∞—Å—Ç—è–º: –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞, –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è –∏ —Ç.–¥.
    preferences: Dict[str, any]
    performance_history: List[Dict]
    weakness_areas: List[str]
    strength_areas: List[str]
    last_updated: datetime

class AdaptiveLearningEngine:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å —Å–∏—Å—Ç–µ–º—ã –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    
    def __init__(self):
        self.skill_areas = [
            'diagnosis', 'communication', 'empathy', 'clinical_reasoning',
            'patient_management', 'treatment_planning', 'emergency_response'
        ]
        
    def analyze_user_performance(self, user_id: int, recent_attempts: List[Dict]) -> UserProfile:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–æ–∑–¥–∞–µ—Ç/–æ–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            recent_attempts: –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
            
        Returns:
            UserProfile: –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è
        learning_style = self._determine_learning_style(recent_attempts)
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º —É—Ä–æ–≤–Ω–∏ –Ω–∞–≤—ã–∫–æ–≤ –ø–æ –æ–±–ª–∞—Å—Ç—è–º
        skill_levels = self._assess_skill_levels(recent_attempts)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
        preferences = self._extract_preferences(recent_attempts)
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–ª–∞–±—ã–µ –∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
        weakness_areas, strength_areas = self._identify_strengths_weaknesses(recent_attempts)
        
        return UserProfile(
            user_id=user_id,
            learning_style=learning_style,
            skill_levels=skill_levels,
            preferences=preferences,
            performance_history=recent_attempts,
            weakness_areas=weakness_areas,
            strength_areas=strength_areas,
            last_updated=datetime.utcnow()
        )
    
    def _determine_learning_style(self, attempts: List[Dict]) -> LearningStyle:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–≤–µ–¥–µ–Ω–∏—è"""
        if not attempts:
            return LearningStyle.SYSTEMATIC  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Ä–µ–º—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
        decision_times = []
        empathy_scores = []
        systematic_choices = 0
        
        for attempt in attempts:
            history = json.loads(attempt.get('dialogue_history', '{}'))
            decisions = history.get('decisions', [])
            
            for decision in decisions:
                # –í—Ä–µ–º—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏—è
                if 'decision_time' in decision:
                    decision_times.append(decision['decision_time'])
                
                # –≠–º–ø–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è
                if 'factors' in decision and 'empathy' in decision['factors']:
                    empathy_scores.append(decision['factors']['empathy'])
                
                # –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è (—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª—É)
                option_text = decision.get('option_text', '').lower()
                if any(word in option_text for word in ['–æ—Å–º–æ—Ç—Ä', '–∞–Ω–∞–º–Ω–µ–∑', '—Ç–µ—Å—Ç', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ']):
                    systematic_choices += 1
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        avg_decision_time = np.mean(decision_times) if decision_times else 30
        avg_empathy = np.mean(empathy_scores) if empathy_scores else 1.0
        systematic_ratio = systematic_choices / len([d for a in attempts for d in json.loads(a.get('dialogue_history', '{}')).get('decisions', [])])
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∏–ª—å
        if avg_empathy > 1.1 and systematic_ratio < 0.5:
            return LearningStyle.EMPATHETIC
        elif avg_decision_time > 45 and systematic_ratio > 0.7:
            return LearningStyle.ANALYTICAL
        elif avg_decision_time < 15:
            return LearningStyle.INTUITIVE
        elif systematic_ratio > 0.6:
            return LearningStyle.SYSTEMATIC
        else:
            return LearningStyle.VISUAL
    
    def _assess_skill_levels(self, attempts: List[Dict]) -> Dict[str, SkillLevel]:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —É—Ä–æ–≤–Ω–∏ –Ω–∞–≤—ã–∫–æ–≤ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –æ–±–ª–∞—Å—Ç—è–º"""
        skill_scores = {area: [] for area in self.skill_areas}
        
        for attempt in attempts:
            scenario_score = attempt.get('score', 0)
            max_score = attempt.get('max_score', 100)
            percentage = (scenario_score / max_score) * 100 if max_score > 0 else 0
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤
            history = json.loads(attempt.get('dialogue_history', '{}'))
            decisions = history.get('decisions', [])
            
            # –î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏
            diagnosis_decisions = [d for d in decisions if '–¥–∏–∞–≥–Ω–æ—Å—Ç' in d.get('option_text', '').lower() or '–æ—Å–º–æ—Ç—Ä' in d.get('option_text', '').lower()]
            if diagnosis_decisions:
                avg_diagnosis_score = np.mean([d.get('final_score', 0) for d in diagnosis_decisions])
                skill_scores['diagnosis'].append(avg_diagnosis_score)
            
            # –ö–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏
            comm_decisions = [d for d in decisions if any(word in d.get('option_text', '').lower() for word in ['–æ–±—ä—è—Å–Ω', '—Ä–∞—Å—Å–∫–∞–∂', '—Å–ø—Ä–æ—Å', '–≤—ã—Å–ª—É—à'])]
            if comm_decisions:
                avg_comm_score = np.mean([d.get('final_score', 0) for d in comm_decisions])
                skill_scores['communication'].append(avg_comm_score)
            
            # –≠–º–ø–∞—Ç–∏—è
            empathy_factors = [d.get('factors', {}).get('empathy', 1.0) for d in decisions if 'factors' in d]
            if empathy_factors:
                skill_scores['empathy'].append(np.mean(empathy_factors) * 50)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–Ω–∏ –Ω–∞–≤—ã–∫–æ–≤
        skill_levels = {}
        for area, scores in skill_scores.items():
            if not scores:
                skill_levels[area] = SkillLevel.BEGINNER
                continue
                
            avg_score = np.mean(scores)
            if avg_score >= 15:
                skill_levels[area] = SkillLevel.EXPERT
            elif avg_score >= 10:
                skill_levels[area] = SkillLevel.ADVANCED
            elif avg_score >= 5:
                skill_levels[area] = SkillLevel.INTERMEDIATE
            else:
                skill_levels[area] = SkillLevel.BEGINNER
        
        return skill_levels
    
    def _extract_preferences(self, attempts: List[Dict]) -> Dict[str, any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –ø–æ–≤–µ–¥–µ–Ω–∏—è"""
        preferences = {
            'scenario_length': 'medium',
            'difficulty_preference': 'adaptive',
            'feedback_frequency': 'medium',
            'hint_usage': False,
            'detailed_explanations': True
        }
        
        if not attempts:
            return preferences
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –¥–ª–∏–Ω—ã —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        scenario_lengths = [len(json.loads(a.get('dialogue_history', '{}')).get('decisions', [])) for a in attempts]
        avg_length = np.mean(scenario_lengths) if scenario_lengths else 5
        
        if avg_length > 8:
            preferences['scenario_length'] = 'long'
        elif avg_length < 4:
            preferences['scenario_length'] = 'short'
        
        # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        completion_rates = []
        for attempt in attempts:
            if attempt.get('completed', False):
                score_ratio = attempt.get('score', 0) / attempt.get('max_score', 100)
                completion_rates.append(score_ratio)
        
        if completion_rates:
            avg_completion = np.mean(completion_rates)
            if avg_completion > 0.8:
                preferences['difficulty_preference'] = 'challenging'
            elif avg_completion < 0.4:
                preferences['difficulty_preference'] = 'easier'
        
        return preferences
    
    def _identify_strengths_weaknesses(self, attempts: List[Dict]) -> Tuple[List[str], List[str]]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        area_scores = {area: [] for area in self.skill_areas}
        
        for attempt in attempts:
            history = json.loads(attempt.get('dialogue_history', '{}'))
            decisions = history.get('decisions', [])
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ä–µ—à–µ–Ω–∏—è –ø–æ –æ–±–ª–∞—Å—Ç—è–º
            for decision in decisions:
                option_text = decision.get('option_text', '').lower()
                score = decision.get('final_score', 0)
                
                if any(word in option_text for word in ['–¥–∏–∞–≥–Ω–æ—Å—Ç', '–æ—Å–º–æ—Ç—Ä', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω']):
                    area_scores['diagnosis'].append(score)
                elif any(word in option_text for word in ['–æ–±—ä—è—Å–Ω', '—Ä–∞—Å—Å–∫–∞–∂', '—Å–æ–æ–±—â']):
                    area_scores['communication'].append(score)
                elif any(word in option_text for word in ['–ø–æ–Ω–∏–º–∞', '—Å–æ—á—É–≤—Å—Ç–≤', '–ø–æ–¥–¥–µ—Ä–∂']):
                    area_scores['empathy'].append(score)
                elif any(word in option_text for word in ['–ª–µ—á–µ–Ω', '—Ç–µ—Ä–∞–ø', '–ø—Ä–æ—Ü–µ–¥—É—Ä']):
                    area_scores['treatment_planning'].append(score)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –±–∞–ª–ª—ã –ø–æ –æ–±–ª–∞—Å—Ç—è–º
        area_averages = {}
        for area, scores in area_scores.items():
            if scores:
                area_averages[area] = np.mean(scores)
            else:
                area_averages[area] = 0
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∏–ª—å–Ω—ã–µ –∏ —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
        sorted_areas = sorted(area_averages.items(), key=lambda x: x[1])
        
        weakness_areas = [area for area, score in sorted_areas[:2] if score < 5]
        strength_areas = [area for area, score in sorted_areas[-2:] if score > 8]
        
        return weakness_areas, strength_areas
    
    def recommend_next_scenarios(self, user_profile: UserProfile, available_scenarios: List[Dict]) -> List[Dict]:
        """
        –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            user_profile: –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            available_scenarios: –î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
            
        Returns:
            List[Dict]: –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
        """
        recommendations = []
        
        for scenario in available_scenarios:
            score = self._calculate_scenario_relevance(user_profile, scenario)
            recommendations.append({
                'scenario': scenario,
                'relevance_score': score,
                'recommendation_reason': self._get_recommendation_reason(user_profile, scenario, score)
            })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        recommendations.sort(key=lambda x: x['relevance_score'], reverse=True)
        
        return recommendations[:5]  # –¢–æ–ø 5 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
    
    def _calculate_scenario_relevance(self, user_profile: UserProfile, scenario: Dict) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        relevance_score = 0.0
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–π
        scenario_data = json.loads(scenario.get('scenario_data', '{}'))
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        for weakness in user_profile.weakness_areas:
            if self._scenario_addresses_skill(scenario_data, weakness):
                relevance_score += 3.0
        
        # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Ä–æ–≤–Ω—é –Ω–∞–≤—ã–∫–æ–≤
        scenario_difficulty = self._assess_scenario_difficulty(scenario_data)
        user_avg_skill = np.mean([skill.value for skill in user_profile.skill_levels.values()])
        
        # –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –Ω–µ–º–Ω–æ–≥–æ –≤—ã—à–µ —Ç–µ–∫—É—â–µ–≥–æ —É—Ä–æ–≤–Ω—è
        if scenario_difficulty == user_avg_skill + 0.5:
            relevance_score += 2.0
        elif abs(scenario_difficulty - user_avg_skill) <= 1.0:
            relevance_score += 1.0
        
        # –£—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è
        if self._scenario_matches_learning_style(scenario_data, user_profile.learning_style):
            relevance_score += 1.5
        
        # –ò–∑–±–µ–≥–∞–µ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –Ω–µ–¥–∞–≤–Ω–æ –ø—Ä–æ–π–¥–µ–Ω–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
        recent_scenarios = [attempt.get('scenario_id') for attempt in user_profile.performance_history[-5:]]
        if scenario.get('id') in recent_scenarios:
            relevance_score -= 2.0
        
        return max(0.0, relevance_score)
    
    def _scenario_addresses_skill(self, scenario_data: Dict, skill_area: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Ä–∞–∑–≤–∏–≤–∞–µ—Ç –ª–∏ —Å—Ü–µ–Ω–∞—Ä–∏–π –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –Ω–∞–≤—ã–∫"""
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ —Å—Ü–µ–Ω–∞—Ä–∏–∏
        skill_keywords = {
            'diagnosis': ['–¥–∏–∞–≥–Ω–æ—Å—Ç', '—Å–∏–º–ø—Ç–æ–º', '–ø—Ä–∏–∑–Ω–∞–∫', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω'],
            'communication': ['–æ–±—ä—è—Å–Ω', '—Å–æ–æ–±—â', '—Ä–∞—Å—Å–∫–∞–∂', '–≤–æ–ø—Ä–æ—Å'],
            'empathy': ['–±–µ—Å–ø–æ–∫–æ–π', '–≤–æ–ª–Ω', '—Å—Ç—Ä–∞—Ö', '–ø–æ–¥–¥–µ—Ä–∂'],
            'treatment_planning': ['–ª–µ—á–µ–Ω', '–ø–ª–∞–Ω', '—Ç–µ—Ä–∞–ø', '–ø—Ä–æ—Ü–µ–¥—É—Ä']
        }
        
        keywords = skill_keywords.get(skill_area, [])
        scenario_text = json.dumps(scenario_data).lower()
        
        return any(keyword in scenario_text for keyword in keywords)
    
    def _assess_scenario_difficulty(self, scenario_data: Dict) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏—è"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        dialogue_nodes = scenario_data.get('dialogue_nodes', [])
        
        complexity_factors = {
            'num_nodes': len(dialogue_nodes),
            'avg_options': np.mean([len(node.get('options', [])) for node in dialogue_nodes]) if dialogue_nodes else 0,
            'score_variance': 0  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–±—Ä–æ—Å–∞ –±–∞–ª–ª–æ–≤
        }
        
        # –ü—Ä–æ—Å—Ç–∞—è —Ñ–æ—Ä–º—É–ª–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        difficulty = (complexity_factors['num_nodes'] * 0.1 + 
                     complexity_factors['avg_options'] * 0.3)
        
        return min(4.0, max(1.0, difficulty))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 1-4
    
    def _scenario_matches_learning_style(self, scenario_data: Dict, learning_style: LearningStyle) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏—è —Å—Ç–∏–ª—é –æ–±—É—á–µ–Ω–∏—è"""
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ç–∏–ª–µ–π –æ–±—É—á–µ–Ω–∏—è
        if learning_style == LearningStyle.VISUAL:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–ª–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            return 'image' in json.dumps(scenario_data) or 'visual' in json.dumps(scenario_data)
        
        elif learning_style == LearningStyle.EMPATHETIC:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            return any(emotion in json.dumps(scenario_data) for emotion in ['angry', 'concerned', 'worried', 'happy'])
        
        elif learning_style == LearningStyle.SYSTEMATIC:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏—è
            dialogue_nodes = scenario_data.get('dialogue_nodes', [])
            return len(dialogue_nodes) > 5  # –ë–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
        
        return True  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ–¥—Ö–æ–¥–∏—Ç
    
    def _get_recommendation_reason(self, user_profile: UserProfile, scenario: Dict, score: float) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        reasons = []
        
        if score >= 3.0:
            weakness_areas = [area for area in user_profile.weakness_areas 
                            if self._scenario_addresses_skill(json.loads(scenario.get('scenario_data', '{}')), area)]
            if weakness_areas:
                reasons.append(f"–ü–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –Ω–∞–≤—ã–∫–∏ –≤ –æ–±–ª–∞—Å—Ç–∏: {', '.join(weakness_areas)}")
        
        if score >= 2.0:
            reasons.append("–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤–∞—à–µ–º—É —Ç–µ–∫—É—â–µ–º—É —É—Ä–æ–≤–Ω—é")
        
        if self._scenario_matches_learning_style(json.loads(scenario.get('scenario_data', '{}')), user_profile.learning_style):
            reasons.append(f"–ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –≤–∞—à–µ–≥–æ —Å—Ç–∏–ª—è –æ–±—É—á–µ–Ω–∏—è ({user_profile.learning_style.value})")
        
        return '; '.join(reasons) if reasons else "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –æ–±—â–µ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è"

    def generate_personalized_hints(self, user_profile: UserProfile, current_node: Dict, scenario_context: Dict) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            user_profile: –ü—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            current_node: –¢–µ–∫—É—â–∏–π —É–∑–µ–ª –¥–∏–∞–ª–æ–≥–∞
            scenario_context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å—Ü–µ–Ω–∞—Ä–∏—è
            
        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ–¥—Å–∫–∞–∑–æ–∫
        """
        hints = []
        
        # –ü–æ–¥—Å–∫–∞–∑–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω
        if 'communication' in user_profile.weakness_areas:
            hints.append("üí¨ –ü–æ–º–Ω–∏—Ç–µ –æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–ª—É—à–∞–Ω–∏—è –∏ —ç–º–ø–∞—Ç–∏–∏ –≤ –æ–±—â–µ–Ω–∏–∏ —Å –ø–∞—Ü–∏–µ–Ω—Ç–æ–º")
        
        if 'diagnosis' in user_profile.weakness_areas:
            hints.append("üîç –°–ª–µ–¥—É–π—Ç–µ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É –ø–æ–¥—Ö–æ–¥—É: –∞–Ω–∞–º–Ω–µ–∑ ‚Üí –æ—Å–º–æ—Ç—Ä ‚Üí –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
        
        if 'empathy' in user_profile.weakness_areas:
            patient_emotion = current_node.get('patient_emotion', 'neutral')
            if patient_emotion in ['angry', 'concerned', 'worried']:
                hints.append("‚ù§Ô∏è –ü–∞—Ü–∏–µ–Ω—Ç –≤—ã–≥–ª—è–¥–∏—Ç –æ–±–µ—Å–ø–æ–∫–æ–µ–Ω–Ω—ã–º. –ü—Ä–æ—è–≤–∏—Ç–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É")
        
        # –ü–æ–¥—Å–∫–∞–∑–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∏–ª—è –æ–±—É—á–µ–Ω–∏—è
        if user_profile.learning_style == LearningStyle.SYSTEMATIC:
            hints.append("üìã –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∫–ª–∏–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞")
        
        elif user_profile.learning_style == LearningStyle.ANALYTICAL:
            hints.append("üß† –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –ø—Ä–∏–Ω—è—Ç–∏–µ–º —Ä–µ—à–µ–Ω–∏—è")
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏
        if current_node.get('clinical_phase') == 'examination':
            hints.append("üë®‚Äç‚öïÔ∏è –ü—Ä–∏ –æ—Å–º–æ—Ç—Ä–µ –æ–±—Ä–∞—â–∞–π—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –ø–∞–ª—å–ø–∞—Ü–∏—é")
        
        return hints[:3]  # –ú–∞–∫—Å–∏–º—É–º 3 –ø–æ–¥—Å–∫–∞–∑–∫–∏, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å

    # ===== –ù–û–í–´–ï ML –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø (—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º—ã) =====
    
    def predict_big_exam_success(self, user_id: int) -> Dict[str, Any]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —É—Å–ø–µ—Ö–∞ –Ω–∞ BIG —ç–∫–∑–∞–º–µ–Ω–µ
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ + –Ω–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        """
        try:
            # –õ–æ–≥–≥–µ—Ä –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            self.logger = getattr(self, 'logger', logging.getLogger(__name__))
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∞–Ω–∞–ª–∏–∑
            from models import VirtualPatientAttempt, UserProgress, TestAttempt
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            recent_attempts_data = self._get_user_attempts_data(user_id)
            if not recent_attempts_data:
                return self._fallback_prediction()
            
            user_profile = self.analyze_user_performance(user_id, recent_attempts_data)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            extended_metrics = self._collect_extended_metrics(user_id)
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞
            success_probability = self._calculate_success_probability(
                user_profile, recent_attempts_data, extended_metrics
            )
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–∞–±—ã–µ –æ–±–ª–∞—Å—Ç–∏
            weak_areas = self._identify_exam_weak_areas(user_id, user_profile)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = self._generate_exam_recommendations(
                weak_areas, success_probability, user_profile
            )
            
            return {
                'success_probability': success_probability,
                'confidence_level': self._calculate_confidence(user_id, extended_metrics),
                'weak_areas': weak_areas,
                'recommendations': recommendations,
                'optimal_exam_date': self._suggest_optimal_exam_date(user_id, user_profile),
                'required_study_hours': self._estimate_study_hours(user_id, user_profile),
                'emotional_state': self._analyze_emotional_state(user_id, recent_attempts_data),
                'readiness_score': self._calculate_readiness_score(user_profile, extended_metrics),
                'timestamp': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"BIG exam prediction error for user {user_id}: {e}")
            return self._fallback_prediction()
    
    def _get_user_attempts_data(self, user_id: int) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ–ø—ã—Ç–æ–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            from models import db, VirtualPatientAttempt
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 –ø–æ–ø—ã—Ç–æ–∫
            attempts = db.session.query(VirtualPatientAttempt).filter_by(
                user_id=user_id,
                completed=True
            ).order_by(VirtualPatientAttempt.completed_at.desc()).limit(20).all()
            
            attempts_data = []
            for attempt in attempts:
                attempts_data.append({
                    'scenario_id': attempt.scenario_id,
                    'score': attempt.score,
                    'max_score': attempt.max_score or 100,
                    'dialogue_history': attempt.dialogue_history or '{}',
                    'completed': attempt.completed,
                    'time_spent': attempt.time_spent or 0,
                    'completed_at': attempt.completed_at.isoformat() if attempt.completed_at else None
                })
            
            return attempts_data
            
        except Exception as e:
            self.logger.error(f"Error getting user attempts data: {e}")
            return []
    
    def _collect_extended_metrics(self, user_id: int) -> Dict[str, float]:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        try:
            from models import db, UserProgress, TestAttempt, VirtualPatientAttempt
            
            metrics = {
                'total_study_sessions': 0,
                'avg_session_duration': 0,
                'consistency_score': 0,
                'improvement_rate': 0,
                'test_performance': 0,
                'virtual_patient_performance': 0,
                'recent_activity_level': 0,
                'streak_days': 0
            }
            
            # –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è
            total_progress = db.session.query(UserProgress).filter_by(
                user_id=user_id, completed=True
            ).count()
            
            # –¢–µ—Å—Ç–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
            thirty_days_ago = datetime.utcnow() - timedelta(days=30)
            recent_tests = db.session.query(TestAttempt).filter(
                TestAttempt.user_id == user_id,
                TestAttempt.attempt_date >= thirty_days_ago
            ).all()
            
            if recent_tests:
                correct_answers = sum(1 for test in recent_tests if test.is_correct)
                metrics['test_performance'] = correct_answers / len(recent_tests)
            
            # –í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–µ –ø–∞—Ü–∏–µ–Ω—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π
            recent_vp = db.session.query(VirtualPatientAttempt).filter(
                VirtualPatientAttempt.user_id == user_id,
                VirtualPatientAttempt.completed_at >= thirty_days_ago,
                VirtualPatientAttempt.completed == True
            ).all()
            
            if recent_vp:
                avg_vp_score = np.mean([
                    (attempt.score / (attempt.max_score or 100)) 
                    for attempt in recent_vp 
                    if attempt.max_score and attempt.max_score > 0
                ])
                metrics['virtual_patient_performance'] = avg_vp_score
                
                # –†–∞—Å—á–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ (–Ω–∏–∑–∫–æ–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ = –≤—ã—Å–æ–∫–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å)
                vp_scores = [
                    (attempt.score / (attempt.max_score or 100)) 
                    for attempt in recent_vp 
                    if attempt.max_score and attempt.max_score > 0
                ]
                if len(vp_scores) > 1:
                    metrics['consistency_score'] = 1.0 - min(1.0, np.std(vp_scores))
                
                # –£—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                metrics['recent_activity_level'] = min(1.0, len(recent_vp) / 10.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 10 –ø–æ–ø—ã—Ç–∫–∞–º
            
            # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            metrics['total_study_sessions'] = total_progress
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"Error collecting extended metrics: {e}")
            return {key: 0.0 for key in [
                'total_study_sessions', 'avg_session_duration', 'consistency_score',
                'improvement_rate', 'test_performance', 'virtual_patient_performance',
                'recent_activity_level', 'streak_days'
            ]}
    
    def _calculate_success_probability(self, user_profile: UserProfile, 
                                     performance_data: List[Dict], 
                                     metrics: Dict[str, float]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ë–∞–∑–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–≤—ã–∫–æ–≤
            skill_score = 0.0
            skill_count = 0
            
            for skill_area, skill_level in user_profile.skill_levels.items():
                if skill_level == SkillLevel.EXPERT:
                    skill_score += 4.0
                elif skill_level == SkillLevel.ADVANCED:
                    skill_score += 3.0
                elif skill_level == SkillLevel.INTERMEDIATE:
                    skill_score += 2.0
                else:  # BEGINNER
                    skill_score += 1.0
                skill_count += 1
            
            avg_skill_score = skill_score / max(1, skill_count)
            base_probability = min(0.9, avg_skill_score / 4.0)  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-0.9
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
            performance_bonus = 0.0
            
            # –ë–æ–Ω—É—Å –∑–∞ —Ö–æ—Ä–æ—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–µ—Å—Ç–∞—Ö
            if metrics['test_performance'] > 0.8:
                performance_bonus += 0.1
            elif metrics['test_performance'] > 0.6:
                performance_bonus += 0.05
            
            # –ë–æ–Ω—É—Å –∑–∞ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã—Ö –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤
            if metrics['virtual_patient_performance'] > 0.8:
                performance_bonus += 0.1
            elif metrics['virtual_patient_performance'] > 0.6:
                performance_bonus += 0.05
            
            # –ë–æ–Ω—É—Å –∑–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
            if metrics['consistency_score'] > 0.8:
                performance_bonus += 0.05
            
            # –ë–æ–Ω—É—Å –∑–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            if metrics['recent_activity_level'] > 0.7:
                performance_bonus += 0.05
            
            # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∞–±—ã–µ –æ–±–ª–∞—Å—Ç–∏
            weakness_penalty = len(user_profile.weakness_areas) * 0.05
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
            final_probability = base_probability + performance_bonus - weakness_penalty
            
            return max(0.1, min(0.95, final_probability))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 10%-95%
            
        except Exception as e:
            self.logger.error(f"Error calculating success probability: {e}")
            return 0.5  # –°—Ä–µ–¥–Ω—è—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–∞–∫ fallback
    
    def _identify_exam_weak_areas(self, user_id: int, user_profile: UserProfile) -> List[Dict]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–ª–∞–±—ã–µ –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è BIG —ç–∫–∑–∞–º–µ–Ω–∞"""
        try:
            weak_areas_detailed = []
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–∞–±—ã–µ –æ–±–ª–∞—Å—Ç–∏ –∏–∑ –ø—Ä–æ—Ñ–∏–ª—è
            for weakness in user_profile.weakness_areas:
                area_info = {
                    'area': weakness,
                    'severity': 'high',
                    'description': self._get_weakness_description(weakness),
                    'improvement_suggestions': self._get_improvement_suggestions(weakness)
                }
                weak_areas_detailed.append(area_info)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±–ª–∞—Å—Ç–∏ —Å–æ —Å—Ä–µ–¥–Ω–∏–º–∏ –Ω–∞–≤—ã–∫–∞–º–∏ –∫–∞–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
            for area, skill_level in user_profile.skill_levels.items():
                if area not in user_profile.weakness_areas and skill_level in [SkillLevel.BEGINNER, SkillLevel.INTERMEDIATE]:
                    area_info = {
                        'area': area,
                        'severity': 'medium' if skill_level == SkillLevel.INTERMEDIATE else 'high',
                        'description': self._get_weakness_description(area),
                        'improvement_suggestions': self._get_improvement_suggestions(area)
                    }
                    weak_areas_detailed.append(area_info)
            
            return weak_areas_detailed[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 –æ–±–ª–∞—Å—Ç–µ–π
            
        except Exception as e:
            self.logger.error(f"Error identifying exam weak areas: {e}")
            return []
    
    def _get_weakness_description(self, area: str) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Å–ª–∞–±–æ–π –æ–±–ª–∞—Å—Ç–∏"""
        descriptions = {
            'diagnosis': '–î–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏ —Ç—Ä–µ–±—É—é—Ç —É–ª—É—á—à–µ–Ω–∏—è. –í–∞–∂–Ω–æ —Ä–∞–∑–≤–∏–≤–∞—Ç—å —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–¥—Ö–æ–¥ –∫ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–µ –¥–∏–∞–≥–Ω–æ–∑–∞.',
            'communication': '–ö–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ —Ä–∞–∑–≤–∏—Ç–∏–∏. –†–∞–±–æ—Ç–∞–π—Ç–µ –Ω–∞–¥ –∞–∫—Ç–∏–≤–Ω—ã–º —Å–ª—É—à–∞–Ω–∏–µ–º –∏ —ç–º–ø–∞—Ç–∏–µ–π.',
            'empathy': '–≠–º–ø–∞—Ç–∏—á–µ—Å–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å. –ë–æ–ª—å—à–µ –≤–Ω–∏–º–∞–Ω–∏—è –∫ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤.',
            'clinical_reasoning': '–ö–ª–∏–Ω–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∞–∫—Ç–∏–∫–∏. –†–∞–∑–≤–∏–≤–∞–π—Ç–µ –ª–æ–≥–∏—á–µ—Å–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏–π.',
            'patient_management': '–ù–∞–≤—ã–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ü–∏–µ–Ω—Ç–∞–º–∏ –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ —É–ª—É—á—à–µ–Ω–∏–∏.',
            'treatment_planning': '–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–µ—á–µ–Ω–∏—è —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è.',
            'emergency_response': '–ù–∞–≤—ã–∫–∏ —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–≥–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω—É–∂–Ω–æ —Ä–∞–∑–≤–∏–≤–∞—Ç—å.'
        }
        return descriptions.get(area, f'–û–±–ª–∞—Å—Ç—å {area} —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è.')
    
    def _get_improvement_suggestions(self, area: str) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
        suggestions = {
            'diagnosis': [
                '–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –∞–Ω–∞–º–Ω–µ–∑–∞',
                '–ò–∑—É—á–∏—Ç–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞–ª—å–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É',
                '–ë–æ–ª—å—à–µ —Ä–∞–±–æ—Ç–∞–π—Ç–µ —Å –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–º–∏ —Å–ª—É—á–∞—è–º–∏'
            ],
            'communication': [
                '–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ –∞–∫—Ç–∏–≤–Ω–æ–µ —Å–ª—É—à–∞–Ω–∏–µ',
                '–†–∞–±–æ—Ç–∞–π—Ç–µ –Ω–∞–¥ —Ä–∞–∑—ä—è—Å–Ω–µ–Ω–∏–µ–º —Å–ª–æ–∂–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤',
                '–†–∞–∑–≤–∏–≤–∞–π—Ç–µ –Ω–∞–≤—ã–∫–∏ –Ω–µ–≤–µ—Ä–±–∞–ª—å–Ω–æ–≥–æ –æ–±—â–µ–Ω–∏—è'
            ],
            'empathy': [
                '–û–±—Ä–∞—â–∞–π—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —ç–º–æ—Ü–∏–∏ –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤',
                '–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ —ç–º–ø–∞—Ç–∏—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã',
                '–ò–∑—É—á–∏—Ç–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—é –ø–∞—Ü–∏–µ–Ω—Ç–æ–≤'
            ]
        }
        return suggestions.get(area, ['–£–¥–µ–ª–∏—Ç–µ –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –ø—Ä–∞–∫—Ç–∏–∫–µ –≤ —ç—Ç–æ–π –æ–±–ª–∞—Å—Ç–∏'])
    
    def _generate_exam_recommendations(self, weak_areas: List[Dict], 
                                     probability: float, 
                                     user_profile: UserProfile) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏"""
        try:
            recommendations = []
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞
            if probability < 0.4:
                recommendations.append({
                    'type': 'urgent',
                    'title': '–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞',
                    'description': '–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å –≤—Ä–µ–º—è –∏–∑—É—á–µ–Ω–∏—è –∏ —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ —Å–ª–∞–±—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö',
                    'priority': 'high'
                })
            elif probability < 0.7:
                recommendations.append({
                    'type': 'improvement',
                    'title': '–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –∞–∫—Ç–∏–≤–Ω—É—é –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É',
                    'description': '–í—ã –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø—É—Ç–∏, –Ω–æ –µ—Å—Ç—å –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è',
                    'priority': 'medium'
                })
            else:
                recommendations.append({
                    'type': 'maintenance',
                    'title': '–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ —Ç–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å',
                    'description': '–û—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã! –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—É—é –ø—Ä–∞–∫—Ç–∏–∫—É',
                    'priority': 'low'
                })
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–ª–∞–±—ã–º –æ–±–ª–∞—Å—Ç—è–º
            for weak_area in weak_areas[:3]:  # –¢–æ–ø 3 —Å–ª–∞–±—ã–µ –æ–±–ª–∞—Å—Ç–∏
                recommendations.append({
                    'type': 'skill_improvement',
                    'title': f'–£–ª—É—á—à–∏—Ç—å –Ω–∞–≤—ã–∫–∏: {weak_area["area"]}',
                    'description': weak_area['description'],
                    'suggestions': weak_area['improvement_suggestions'],
                    'priority': weak_area['severity']
                })
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç–∏–ª—é –æ–±—É—á–µ–Ω–∏—è
            style_rec = self._get_learning_style_recommendation(user_profile.learning_style)
            if style_rec:
                recommendations.append(style_rec)
            
            return recommendations
            
        except Exception as e:
            self.logger.error(f"Error generating exam recommendations: {e}")
            return [{'type': 'general', 'title': '–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –æ–±—É—á–µ–Ω–∏–µ', 'description': '–†–µ–≥—É–ª—è—Ä–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ - –∫–ª—é—á –∫ —É—Å–ø–µ—Ö—É'}]
    
    def _get_learning_style_recommendation(self, learning_style: LearningStyle) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∏–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        style_recommendations = {
            LearningStyle.VISUAL: {
                'type': 'learning_style',
                'title': '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã',
                'description': '–ò–∑—É—á–∞–π—Ç–µ –¥–∏–∞–≥—Ä–∞–º–º—ã, —Ä–µ–Ω—Ç–≥–µ–Ω–æ–≤—Å–∫–∏–µ —Å–Ω–∏–º–∫–∏ –∏ –∞–Ω–∞—Ç–æ–º–∏—á–µ—Å–∫–∏–µ –∞—Ç–ª–∞—Å—ã',
                'priority': 'medium'
            },
            LearningStyle.ANALYTICAL: {
                'type': 'learning_style',
                'title': '–£–≥–ª—É–±–ª–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª—É—á–∞–µ–≤',
                'description': '–î–µ—Ç–∞–ª—å–Ω–æ —Ä–∞–∑–±–∏—Ä–∞–π—Ç–µ —Å–ª–æ–∂–Ω—ã–µ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Å–ª—É—á–∞–∏ –∏ –∏–∑—É—á–∞–π—Ç–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è',
                'priority': 'medium'
            },
            LearningStyle.SYSTEMATIC: {
                'type': 'learning_style',
                'title': '–°–ª–µ–¥—É–π—Ç–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞–º',
                'description': '–ò–∑—É—á–∞–π—Ç–µ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã',
                'priority': 'medium'
            },
            LearningStyle.EMPATHETIC: {
                'type': 'learning_style',
                'title': '–ü—Ä–∞–∫—Ç–∏–∫–∞ –æ–±—â–µ–Ω–∏—è —Å –ø–∞—Ü–∏–µ–Ω—Ç–∞–º–∏',
                'description': '–ë–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ–ª—è–π—Ç–µ —Å—Ü–µ–Ω–∞—Ä–∏—è–º —Å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ü–∏–µ–Ω—Ç–∞–º–∏',
                'priority': 'medium'
            }
        }
        return style_recommendations.get(learning_style, None)
    
    def _suggest_optimal_exam_date(self, user_id: int, user_profile: UserProfile) -> Optional[str]:
        """–ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –¥–∞—Ç—É —ç–∫–∑–∞–º–µ–Ω–∞"""
        try:
            # –ë–∞–∑–æ–≤–æ–µ –≤—Ä–µ–º—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–≤—ã–∫–æ–≤
            required_hours = self._estimate_study_hours(user_id, user_profile)
            
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º 10 —á–∞—Å–æ–≤ –æ–±—É—á–µ–Ω–∏—è –≤ –Ω–µ–¥–µ–ª—é
            hours_per_week = 10
            weeks_needed = max(4, int(required_hours / hours_per_week))
            
            # –î–æ–±–∞–≤–ª—è–µ–º –±—É—Ñ–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è
            buffer_weeks = 2
            total_weeks = weeks_needed + buffer_weeks
            
            optimal_date = datetime.utcnow() + timedelta(weeks=total_weeks)
            
            return optimal_date.strftime('%Y-%m-%d')
            
        except Exception as e:
            self.logger.error(f"Error suggesting optimal exam date: {e}")
            return None
    
    def _estimate_study_hours(self, user_id: int, user_profile: UserProfile) -> int:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –≤—Ä–µ–º—è –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏"""
        try:
            base_hours = 80  # –ë–∞–∑–æ–≤–æ–µ –≤—Ä–µ–º—è –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–≤—ã–∫–æ–≤
            skill_adjustment = 0
            for skill_level in user_profile.skill_levels.values():
                if skill_level == SkillLevel.EXPERT:
                    skill_adjustment -= 10
                elif skill_level == SkillLevel.ADVANCED:
                    skill_adjustment -= 5
                elif skill_level == SkillLevel.BEGINNER:
                    skill_adjustment += 15
                # INTERMEDIATE –Ω–µ –∏–∑–º–µ–Ω—è–µ—Ç –±–∞–∑–æ–≤–æ–µ –≤—Ä–µ–º—è
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è —Å–ª–∞–±—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
            weakness_hours = len(user_profile.weakness_areas) * 10
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –Ω–∞ —Å—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è
            style_adjustment = 0
            if user_profile.learning_style == LearningStyle.ANALYTICAL:
                style_adjustment += 20  # –ë–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑
            elif user_profile.learning_style == LearningStyle.INTUITIVE:
                style_adjustment -= 10  # –ë—ã—Å—Ç—Ä–µ–µ —É—Å–≤–∞–∏–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            
            total_hours = base_hours + skill_adjustment + weakness_hours + style_adjustment
            
            return max(40, min(200, total_hours))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 40-200 —á–∞—Å–æ–≤
            
        except Exception as e:
            self.logger.error(f"Error estimating study hours: {e}")
            return 100  # –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∫–∞–∫ fallback
    
    def _analyze_emotional_state(self, user_id: int, attempts_data: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è"""
        try:
            if not attempts_data:
                return {'state': 'neutral', 'confidence': 0.3, 'trends': []}
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö
            performance_trend = []
            time_patterns = []
            
            for attempt in attempts_data:
                if attempt.get('max_score', 0) > 0:
                    score_ratio = attempt['score'] / attempt['max_score']
                    performance_trend.append(score_ratio)
                
                time_spent = attempt.get('time_spent', 0)
                if time_spent > 0:
                    time_patterns.append(time_spent)
            
            emotional_indicators = {
                'performance_variance': np.std(performance_trend) if performance_trend else 0,
                'average_performance': np.mean(performance_trend) if performance_trend else 0,
                'time_consistency': 1.0 - (np.std(time_patterns) / np.mean(time_patterns)) if time_patterns and np.mean(time_patterns) > 0 else 0,
                'recent_trend': self._calculate_recent_trend(performance_trend)
            }
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            emotional_state = self._determine_emotional_state(emotional_indicators)
            
            return {
                'state': emotional_state['state'],
                'confidence': emotional_state['confidence'],
                'indicators': emotional_indicators,
                'suggestions': emotional_state['suggestions'],
                'trends': self._analyze_performance_trends(performance_trend)
            }
            
        except Exception as e:
            self.logger.error(f"Error analyzing emotional state: {e}")
            return {'state': 'neutral', 'confidence': 0.3, 'trends': [], 'suggestions': []}
    
    def _calculate_recent_trend(self, performance_data: List[float]) -> str:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç—Ä–µ–Ω–¥ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        if len(performance_data) < 3:
            return 'insufficient_data'
        
        recent_half = performance_data[-len(performance_data)//2:]
        early_half = performance_data[:len(performance_data)//2]
        
        recent_avg = np.mean(recent_half)
        early_avg = np.mean(early_half)
        
        if recent_avg > early_avg + 0.1:
            return 'improving'
        elif recent_avg < early_avg - 0.1:
            return 'declining'
        else:
            return 'stable'
    
    def _determine_emotional_state(self, indicators: Dict) -> Dict[str, Any]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        performance = indicators['average_performance']
        variance = indicators['performance_variance']
        trend = indicators['recent_trend']
        
        if performance > 0.8 and variance < 0.15 and trend in ['improving', 'stable']:
            return {
                'state': 'confident',
                'confidence': 0.8,
                'suggestions': ['–û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞! –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ', '–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏']
            }
        elif performance < 0.4 or variance > 0.3 or trend == 'declining':
            return {
                'state': 'stressed',
                'confidence': 0.7,
                'suggestions': ['–°–¥–µ–ª–∞–π—Ç–µ –ø–µ—Ä–µ—Ä—ã–≤ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è', '–í–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–º –∑–∞–¥–∞—á–∞–º', '–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–∞ –∫ –æ–±—É—á–µ–Ω–∏—é']
            }
        elif trend == 'improving':
            return {
                'state': 'motivated',
                'confidence': 0.7,
                'suggestions': ['–í–∞—à –ø—Ä–æ–≥—Ä–µ—Å—Å –æ—á–µ–≤–∏–¥–µ–Ω!', '–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ']
            }
        else:
            return {
                'state': 'neutral',
                'confidence': 0.5,
                'suggestions': ['–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—É—é –ø—Ä–∞–∫—Ç–∏–∫—É', '–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–∞—Ä—å–∏—Ä–æ–≤–∞—Ç—å —Ç–∏–ø—ã –∑–∞–¥–∞–Ω–∏–π']
            }
    
    def _analyze_performance_trends(self, performance_data: List[float]) -> List[Dict]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        if len(performance_data) < 5:
            return []
        
        trends = []
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 –ø–æ–ø—ã—Ç–æ–∫
        recent_5 = performance_data[-5:]
        avg_recent = np.mean(recent_5)
        
        if avg_recent > 0.8:
            trends.append({'type': 'positive', 'description': '–°—Ç–∞–±–∏–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã'})
        elif avg_recent < 0.4:
            trends.append({'type': 'concerning', 'description': '–ù–∏–∑–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è'})
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        std_recent = np.std(recent_5)
        if std_recent < 0.1:
            trends.append({'type': 'stable', 'description': '–°—Ç–∞–±–∏–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'})
        elif std_recent > 0.3:
            trends.append({'type': 'volatile', 'description': '–ù–µ—É—Å—Ç–æ–π—á–∏–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã'})
        
        return trends
    
    def _calculate_confidence(self, user_id: int, metrics: Dict[str, float]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏"""
        try:
            confidence_factors = {
                'data_availability': min(1.0, metrics.get('total_study_sessions', 0) / 20.0),
                'recent_activity': metrics.get('recent_activity_level', 0),
                'consistency': metrics.get('consistency_score', 0),
                'test_data': 1.0 if metrics.get('test_performance', 0) > 0 else 0.3
            }
            
            # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ —Ñ–∞–∫—Ç–æ—Ä–æ–≤
            weights = [0.3, 0.3, 0.2, 0.2]
            confidence = sum(factor * weight for factor, weight in zip(confidence_factors.values(), weights))
            
            return max(0.3, min(0.9, confidence))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 30%-90%
            
        except Exception as e:
            self.logger.error(f"Error calculating confidence: {e}")
            return 0.5
    
    def _calculate_readiness_score(self, user_profile: UserProfile, metrics: Dict[str, float]) -> float:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–∏–π –±–∞–ª–ª –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ —ç–∫–∑–∞–º–µ–Ω—É"""
        try:
            # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
            skill_score = np.mean([
                4.0 if skill == SkillLevel.EXPERT else
                3.0 if skill == SkillLevel.ADVANCED else
                2.0 if skill == SkillLevel.INTERMEDIATE else 1.0
                for skill in user_profile.skill_levels.values()
            ]) / 4.0  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 0-1
            
            practice_score = min(1.0, metrics.get('recent_activity_level', 0))
            consistency_score = metrics.get('consistency_score', 0)
            test_score = metrics.get('test_performance', 0)
            
            # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∞–±—ã–µ –æ–±–ª–∞—Å—Ç–∏
            weakness_penalty = len(user_profile.weakness_areas) * 0.1
            
            # –ò—Ç–æ–≥–æ–≤—ã–π –±–∞–ª–ª
            readiness = (skill_score * 0.4 + practice_score * 0.2 + 
                        consistency_score * 0.2 + test_score * 0.2) - weakness_penalty
            
            return max(0.0, min(1.0, readiness))
            
        except Exception as e:
            self.logger.error(f"Error calculating readiness score: {e}")
            return 0.5
    
    def _fallback_prediction(self) -> Dict[str, Any]:
        """–ë–∞–∑–æ–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –µ—Å–ª–∏ ML –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
        return {
            'success_probability': 0.5,
            'confidence_level': 0.3,
            'weak_areas': [],
            'recommendations': [
                {
                    'type': 'general',
                    'title': '–ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –æ–±—É—á–µ–Ω–∏–µ',
                    'description': '–†–µ–≥—É–ª—è—Ä–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞ –ø–æ–º–æ–∂–µ—Ç —É–ª—É—á—à–∏—Ç—å –≤–∞—à–∏ –Ω–∞–≤—ã–∫–∏',
                    'priority': 'medium'
                }
            ],
            'optimal_exam_date': (datetime.utcnow() + timedelta(weeks=12)).strftime('%Y-%m-%d'),
            'required_study_hours': 100,
            'emotional_state': {'state': 'neutral', 'confidence': 0.3, 'trends': []},
            'readiness_score': 0.5,
            'timestamp': datetime.utcnow().isoformat()
        }

# –ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º–æ–π
class AdaptiveLearningService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"""
    
    def __init__(self, db_session):
        self.db = db_session
        self.engine = AdaptiveLearningEngine()
        self.user_profiles = {}  # –ö—ç—à –ø—Ä–æ—Ñ–∏–ª–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
    
    def get_user_profile(self, user_id: int) -> UserProfile:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user_id in self.user_profiles:
            profile = self.user_profiles[user_id]
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å, –µ—Å–ª–∏ –æ–Ω —Å—Ç–∞—Ä—ã–π (–±–æ–ª–µ–µ 7 –¥–Ω–µ–π)
            if datetime.utcnow() - profile.last_updated > timedelta(days=7):
                profile = self.update_user_profile(user_id)
        else:
            profile = self.update_user_profile(user_id)
        
        return profile
    
    def update_user_profile(self, user_id: int) -> UserProfile:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        from models import VirtualPatientAttempt
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10)
        recent_attempts = self.db.query(VirtualPatientAttempt).filter_by(
            user_id=user_id,
            completed=True
        ).order_by(VirtualPatientAttempt.completed_at.desc()).limit(10).all()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        attempts_data = []
        for attempt in recent_attempts:
            attempts_data.append({
                'scenario_id': attempt.scenario_id,
                'score': attempt.score,
                'max_score': attempt.scenario.max_score,
                'dialogue_history': attempt.dialogue_history,
                'completed': attempt.completed,
                'time_spent': attempt.time_spent
            })
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å
        profile = self.engine.analyze_user_performance(user_id, attempts_data)
        
        # –ö—ç—à–∏—Ä—É–µ–º –ø—Ä–æ—Ñ–∏–ª—å
        self.user_profiles[user_id] = profile
        
        return profile
    
    def get_scenario_recommendations(self, user_id: int, available_scenarios: List) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        profile = self.get_user_profile(user_id)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ü–µ–Ω–∞—Ä–∏–∏ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        scenarios_data = []
        for scenario in available_scenarios:
            scenarios_data.append({
                'id': scenario.id,
                'title': scenario.title,
                'scenario_data': scenario.scenario_data,
                'difficulty': scenario.difficulty,
                'category': getattr(scenario, 'category', 'general')
            })
        
        return self.engine.recommend_next_scenarios(profile, scenarios_data)
    
    def get_personalized_hints(self, user_id: int, current_node: Dict, scenario_context: Dict) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏"""
        profile = self.get_user_profile(user_id)
        return self.engine.generate_personalized_hints(profile, current_node, scenario_context)

    # ===== –ù–û–í–´–ï –ú–ï–¢–û–î–´ –î–õ–Ø ML –ò–ù–¢–ï–ì–†–ê–¶–ò–ò =====
    
    def get_big_exam_prediction(self, user_id: int) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ BIG —ç–∫–∑–∞–º–µ–Ω—É
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            Dict: –î–µ—Ç–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        try:
            return self.engine.predict_big_exam_success(user_id)
        except Exception as e:
            logging.error(f"Error getting BIG exam prediction for user {user_id}: {e}")
            return self.engine._fallback_prediction()
    
    def get_personalized_study_plan(self, user_id: int, target_exam_date: str = None) -> Dict[str, Any]:
        """
        –°–æ–∑–¥–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            target_exam_date: –¶–µ–ª–µ–≤–∞—è –¥–∞—Ç–∞ —ç–∫–∑–∞–º–µ–Ω–∞ (YYYY-MM-DD)
            
        Returns:
            Dict: –ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è
        """
        try:
            exam_prediction = self.get_big_exam_prediction(user_id)
            profile = self.get_user_profile(user_id)
            
            # –ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—É—é
            if not target_exam_date:
                target_exam_date = exam_prediction.get('optimal_exam_date')
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è –¥–æ —ç–∫–∑–∞–º–µ–Ω–∞
            if target_exam_date:
                try:
                    exam_date = datetime.strptime(target_exam_date, '%Y-%m-%d')
                    days_until_exam = (exam_date - datetime.utcnow()).days
                except ValueError:
                    days_until_exam = 84  # 12 –Ω–µ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            else:
                days_until_exam = 84
            
            # –°–æ–∑–¥–∞–µ–º –ø–ª–∞–Ω
            study_plan = {
                'user_id': user_id,
                'target_exam_date': target_exam_date,
                'days_until_exam': max(1, days_until_exam),
                'total_required_hours': exam_prediction.get('required_study_hours', 100),
                'hours_per_week': max(5, exam_prediction.get('required_study_hours', 100) / max(1, days_until_exam // 7)),
                'current_readiness': exam_prediction.get('readiness_score', 0.5),
                'success_probability': exam_prediction.get('success_probability', 0.5),
                'weak_areas': exam_prediction.get('weak_areas', []),
                'weekly_schedule': self._generate_weekly_schedule(profile, exam_prediction, days_until_exam),
                'milestones': self._generate_study_milestones(days_until_exam, exam_prediction),
                'adaptive_adjustments': self._get_adaptive_adjustments(profile, exam_prediction),
                'timestamp': datetime.utcnow().isoformat()
            }
            
            return study_plan
            
        except Exception as e:
            logging.error(f"Error creating study plan for user {user_id}: {e}")
            return self._fallback_study_plan(user_id, target_exam_date)
    
    def _generate_weekly_schedule(self, profile: 'UserProfile', prediction: Dict, days_until_exam: int) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è"""
        weeks_until_exam = max(1, days_until_exam // 7)
        total_hours = prediction.get('required_study_hours', 100)
        hours_per_week = total_hours / weeks_until_exam
        
        schedule = []
        weak_areas = [area['area'] for area in prediction.get('weak_areas', [])]
        
        for week in range(min(12, weeks_until_exam)):  # –ú–∞–∫—Å–∏–º—É–º 12 –Ω–µ–¥–µ–ª—å
            week_plan = {
                'week_number': week + 1,
                'total_hours': min(25, max(5, hours_per_week)),  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 5-25 —á–∞—Å–æ–≤ –≤ –Ω–µ–¥–µ–ª—é
                'focus_areas': self._get_weekly_focus(week, weeks_until_exam, weak_areas, profile),
                'activities': self._get_weekly_activities(week, weeks_until_exam, profile),
                'assessment': f"–°–∞–º–æ–æ—Ü–µ–Ω–∫–∞ –ø–æ—Å–ª–µ –Ω–µ–¥–µ–ª–∏ {week + 1}"
            }
            schedule.append(week_plan)
        
        return schedule
    
    def _get_weekly_focus(self, week: int, total_weeks: int, weak_areas: List[str], profile: 'UserProfile') -> List[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ñ–æ–∫—É—Å –Ω–µ–¥–µ–ª–∏"""
        if week < total_weeks * 0.6:  # –ü–µ—Ä–≤—ã–µ 60% –≤—Ä–µ–º–µ–Ω–∏ - —Ä–∞–±–æ—Ç–∞ —Å–æ —Å–ª–∞–±—ã–º–∏ –æ–±–ª–∞—Å—Ç—è–º–∏
            return weak_areas[:2] if weak_areas else ['diagnosis', 'communication']
        elif week < total_weeks * 0.8:  # –°–ª–µ–¥—É—é—â–∏–µ 20% - –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞
            return ['clinical_reasoning', 'patient_management']
        else:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 20% - –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ –∏ –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∏–µ
            return ['review', 'mock_exams']
    
    def _get_weekly_activities(self, week: int, total_weeks: int, profile: 'UserProfile') -> List[Dict]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–µ–¥–µ–ª–∏"""
        base_activities = [
            {'type': 'virtual_patients', 'hours': 3, 'description': '–ü—Ä–∞–∫—Ç–∏–∫–∞ —Å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ü–∏–µ–Ω—Ç–∞–º–∏'},
            {'type': 'learning_cards', 'hours': 2, 'description': '–ò–∑—É—á–µ–Ω–∏–µ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫'},
            {'type': 'tests', 'hours': 1, 'description': '–ü—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤'}
        ]
        
        # –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–¥ —Å—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è
        if profile.learning_style == LearningStyle.VISUAL:
            base_activities.append({'type': 'visual_materials', 'hours': 1, 'description': '–ò–∑—É—á–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤'})
        elif profile.learning_style == LearningStyle.ANALYTICAL:
            base_activities.append({'type': 'case_analysis', 'hours': 2, 'description': '–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ª—É—á–∞–µ–≤'})
        elif profile.learning_style == LearningStyle.SYSTEMATIC:
            base_activities.append({'type': 'protocols', 'hours': 1, 'description': '–ò–∑—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤'})
        
        return base_activities
    
    def _generate_study_milestones(self, days_until_exam: int, prediction: Dict) -> List[Dict]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –∫–æ–Ω—Ç—Ä–æ–ª—è"""
        milestones = []
        weeks_until_exam = max(1, days_until_exam // 7)
        
        # –ú–∏–ª–µ—Å—Ç–æ—É–Ω—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–æ —ç–∫–∑–∞–º–µ–Ω–∞
        if weeks_until_exam >= 12:  # –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞
            milestones = [
                {'week': 4, 'goal': '–ó–∞–≤–µ—Ä—à–∏—Ç—å –∏–∑—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Å–ª–∞–±—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π', 'target_score': 0.6},
                {'week': 8, 'goal': '–î–æ—Å—Ç–∏—á—å —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ç–µ—Å—Ç–∞—Ö', 'target_score': 0.7},
                {'week': 10, 'goal': '–ü—Ä–æ–π—Ç–∏ –ø—Ä–æ–±–Ω—ã–π —ç–∫–∑–∞–º–µ–Ω', 'target_score': 0.75},
                {'week': 12, 'goal': '–§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ', 'target_score': 0.8}
            ]
        elif weeks_until_exam >= 8:  # –°—Ä–µ–¥–Ω—è—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞
            milestones = [
                {'week': 3, 'goal': '–£–ª—É—á—à–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏', 'target_score': 0.65},
                {'week': 6, 'goal': '–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞', 'target_score': 0.75},
                {'week': 8, 'goal': '–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —ç–∫–∑–∞–º–µ–Ω—É', 'target_score': 0.8}
            ]
        else:  # –ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞
            milestones = [
                {'week': 2, 'goal': '–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å–æ —Å–ª–∞–±—ã–º–∏ –æ–±–ª–∞—Å—Ç—è–º–∏', 'target_score': 0.7},
                {'week': weeks_until_exam, 'goal': '–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å', 'target_score': 0.75}
            ]
        
        return milestones
    
    def _get_adaptive_adjustments(self, profile: 'UserProfile', prediction: Dict) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞"""
        adjustments = []
        
        success_prob = prediction.get('success_probability', 0.5)
        emotional_state = prediction.get('emotional_state', {}).get('state', 'neutral')
        
        if success_prob < 0.4:
            adjustments.append({
                'type': 'intensity',
                'recommendation': '–£–≤–µ–ª–∏—á–∏—Ç—å –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –Ω–∞ 30%',
                'reason': '–ù–∏–∑–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —É—Å–∏–ª–∏–π'
            })
        
        if emotional_state == 'stressed':
            adjustments.append({
                'type': 'stress_management',
                'recommendation': '–î–æ–±–∞–≤–∏—Ç—å —Ç–µ—Ö–Ω–∏–∫–∏ —Ä–µ–ª–∞–∫—Å–∞—Ü–∏–∏ –∏ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–µ —Å–µ—Å—Å–∏–∏',
                'reason': '–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å—Ç—Ä–µ—Å—Å–∞'
            })
        
        if emotional_state == 'motivated':
            adjustments.append({
                'type': 'challenge',
                'recommendation': '–ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞–Ω–∏–π',
                'reason': '–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –º–æ—Ç–∏–≤–∞—Ü–∏–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–≤–µ–ª–∏—á–∏—Ç—å –Ω–∞–≥—Ä—É–∑–∫—É'
            })
        
        # –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ —Å—Ç–∏–ª—å –æ–±—É—á–µ–Ω–∏—è
        if profile.learning_style == LearningStyle.EMPATHETIC:
            adjustments.append({
                'type': 'learning_style',
                'recommendation': '–ë–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ —É–¥–µ–ª–∏—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏—è–º —Å —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∞—Å–ø–µ–∫—Ç–æ–º',
                'reason': '–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —ç–º–ø–∞—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ç–∏–ª—é –æ–±—É—á–µ–Ω–∏—è'
            })
        
        return adjustments
    
    def _fallback_study_plan(self, user_id: int, target_exam_date: str = None) -> Dict[str, Any]:
        """–ë–∞–∑–æ–≤—ã–π –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö"""
        return {
            'user_id': user_id,
            'target_exam_date': target_exam_date or (datetime.utcnow() + timedelta(weeks=12)).strftime('%Y-%m-%d'),
            'days_until_exam': 84,
            'total_required_hours': 100,
            'hours_per_week': 12,
            'current_readiness': 0.5,
            'success_probability': 0.5,
            'weak_areas': [],
            'weekly_schedule': [
                {
                    'week_number': i,
                    'total_hours': 12,
                    'focus_areas': ['general_practice'],
                    'activities': [
                        {'type': 'virtual_patients', 'hours': 4, 'description': '–ü—Ä–∞–∫—Ç–∏–∫–∞ —Å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ü–∏–µ–Ω—Ç–∞–º–∏'},
                        {'type': 'learning_cards', 'hours': 3, 'description': '–ò–∑—É—á–µ–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤'},
                        {'type': 'tests', 'hours': 2, 'description': '–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ'}
                    ]
                } for i in range(1, 13)
            ],
            'milestones': [
                {'week': 4, 'goal': '–ë–∞–∑–æ–≤–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞', 'target_score': 0.6},
                {'week': 8, 'goal': '–£–≥–ª—É–±–ª–µ–Ω–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞', 'target_score': 0.7},
                {'week': 12, 'goal': '–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —ç–∫–∑–∞–º–µ–Ω—É', 'target_score': 0.8}
            ],
            'adaptive_adjustments': [],
            'timestamp': datetime.utcnow().isoformat()
        }
    
    def track_study_progress(self, user_id: int, study_session: Dict) -> Dict[str, Any]:
        """
        –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –ø–ª–∞–Ω
        
        Args:
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            study_session: –î–∞–Ω–Ω—ã–µ —Å–µ—Å—Å–∏–∏ –æ–±—É—á–µ–Ω–∏—è
            
        Returns:
            Dict: –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            current_prediction = self.get_big_exam_prediction(user_id)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Å—Å–∏—é
            session_analysis = {
                'session_score': study_session.get('score', 0),
                'time_spent': study_session.get('time_spent', 0),
                'areas_practiced': study_session.get('areas', []),
                'difficulty_level': study_session.get('difficulty', 'medium'),
                'emotional_feedback': study_session.get('emotional_state', 'neutral')
            }
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            updated_profile = self.update_user_profile(user_id)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–∞ –ª–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–ª–∞–Ω–∞
            adaptation_needed = self._check_adaptation_needed(
                current_prediction, session_analysis, updated_profile
            )
            
            return {
                'updated_prediction': current_prediction,
                'session_analysis': session_analysis,
                'adaptation_needed': adaptation_needed,
                'next_recommendations': self._get_next_session_recommendations(
                    updated_profile, session_analysis
                ),
                'progress_trend': self._calculate_progress_trend(user_id),
                'timestamp': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            logging.error(f"Error tracking study progress for user {user_id}: {e}")
            return {'error': 'Failed to track progress', 'timestamp': datetime.utcnow().isoformat()}
    
    def _check_adaptation_needed(self, prediction: Dict, session: Dict, profile: 'UserProfile') -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–∞ –ª–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏—è –ø–ª–∞–Ω–∞ –æ–±—É—á–µ–Ω–∏—è"""
        adaptations = []
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ—Å—Å–∏–∏
        session_score = session.get('session_score', 0)
        if session_score < 0.4:  # –ù–∏–∑–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            adaptations.append({
                'type': 'difficulty_reduction',
                'description': '–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–Ω–∏–∑–∏—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞–Ω–∏–π',
                'priority': 'high'
            })
        elif session_score > 0.85:  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            adaptations.append({
                'type': 'difficulty_increase',
                'description': '–ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –ª—É—á—à–µ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞',
                'priority': 'medium'
            })
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        emotional_state = session.get('emotional_feedback', 'neutral')
        if emotional_state == 'frustrated':
            adaptations.append({
                'type': 'support',
                'description': '–î–æ–±–∞–≤–∏—Ç—å –º–æ—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—É—é –ø–æ–¥–¥–µ—Ä–∂–∫—É –∏ –ø–µ—Ä–µ—Ä—ã–≤—ã',
                'priority': 'high'
            })
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
        time_spent = session.get('time_spent', 0)
        if time_spent > 120:  # –ë–æ–ª–µ–µ 2 —á–∞—Å–æ–≤
            adaptations.append({
                'type': 'session_length',
                'description': '–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ—Å—Å–∏–π',
                'priority': 'medium'
            })
        
        return {
            'needed': len(adaptations) > 0,
            'adaptations': adaptations,
            'confidence': 0.8 if adaptations else 0.3
        }
    
    def _get_next_session_recommendations(self, profile: 'UserProfile', last_session: Dict) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —Å–µ—Å—Å–∏–∏"""
        recommendations = []
        
        # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏
        last_score = last_session.get('session_score', 0)
        
        if last_score < 0.5:
            recommendations.append({
                'type': 'review',
                'description': '–ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –º–∞—Ç–µ—Ä–∏–∞–ª –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏',
                'priority': 'high'
            })
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–∞–±—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
        for weakness in profile.weakness_areas[:2]:  # –¢–æ–ø 2 —Å–ª–∞–±—ã–µ –æ–±–ª–∞—Å—Ç–∏
            recommendations.append({
                'type': 'skill_focus',
                'description': f'–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Ç–µ—Å—å –Ω–∞ —É–ª—É—á—à–µ–Ω–∏–∏ –Ω–∞–≤—ã–∫–æ–≤: {weakness}',
                'priority': 'high'
            })
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å—Ç–∏–ª—é –æ–±—É—á–µ–Ω–∏—è
        if profile.learning_style == LearningStyle.VISUAL:
            recommendations.append({
                'type': 'learning_style',
                'description': '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –¥–∏–∞–≥—Ä–∞–º–º—ã',
                'priority': 'medium'
            })
        elif profile.learning_style == LearningStyle.ANALYTICAL:
            recommendations.append({
                'type': 'learning_style',
                'description': '–£–≥–ª—É–±–ª–µ–Ω–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∫–∞–∂–¥—ã–π —Å–ª—É—á–∞–π',
                'priority': 'medium'
            })
        
        return recommendations[:4]  # –ú–∞–∫—Å–∏–º—É–º 4 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    
    def _calculate_progress_trend(self, user_id: int) -> Dict[str, Any]:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç—Ä–µ–Ω–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            from models import VirtualPatientAttempt
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 –ø–æ–ø—ã—Ç–æ–∫
            recent_attempts = self.db.query(VirtualPatientAttempt).filter_by(
                user_id=user_id,
                completed=True
            ).order_by(VirtualPatientAttempt.completed_at.desc()).limit(10).all()
            
            if len(recent_attempts) < 3:
                return {'trend': 'insufficient_data', 'confidence': 0.1}
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥
            scores = []
            for attempt in reversed(recent_attempts):  # –û—Ç —Å—Ç–∞—Ä—ã—Ö –∫ –Ω–æ–≤—ã–º
                if attempt.max_score and attempt.max_score > 0:
                    scores.append(attempt.score / attempt.max_score)
            
            if len(scores) < 3:
                return {'trend': 'insufficient_data', 'confidence': 0.2}
            
            # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–∞
            first_half = scores[:len(scores)//2]
            second_half = scores[len(scores)//2:]
            
            first_avg = np.mean(first_half)
            second_avg = np.mean(second_half)
            
            if second_avg > first_avg + 0.1:
                trend = 'improving'
                confidence = 0.8
            elif second_avg < first_avg - 0.1:
                trend = 'declining'
                confidence = 0.8
            else:
                trend = 'stable'
                confidence = 0.6
            
            return {
                'trend': trend,
                'confidence': confidence,
                'recent_average': second_avg,
                'improvement_rate': second_avg - first_avg,
                'consistency': 1.0 - np.std(scores) if len(scores) > 1 else 0.5
            }
            
        except Exception as e:
            logging.error(f"Error calculating progress trend for user {user_id}: {e}")
            return {'trend': 'error', 'confidence': 0.0}